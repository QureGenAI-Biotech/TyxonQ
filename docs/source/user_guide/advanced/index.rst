===============
Advanced Topics
===============

Advanced features, performance optimization, and framework extension capabilities for TyxonQ. This section covers sophisticated usage patterns, custom implementations, and techniques for achieving maximum performance.

.. contents:: Contents
   :depth: 2
   :local:

Overview
========

The Advanced Topics section provides in-depth coverage of:

ðŸš€ **Performance Optimization**
   Memory management, GPU acceleration, and computational efficiency techniques

ðŸ”§ **Custom Backend Development**
   Creating custom numerical backends and device simulators

ðŸ”Œ **Plugin System**
   Extending TyxonQ with custom compilers, devices, and algorithms

âš¡ **Memory Management**
   Advanced techniques for large-scale quantum simulations

ðŸŽ¯ **Framework Extension**
   Building domain-specific quantum applications on TyxonQ

ðŸ“Š **Profiling and Benchmarking**
   Tools and techniques for performance analysis

Performance Optimization
=========================

Memory Management
-----------------

**Circuit Memory Optimization**

Large quantum circuits can consume significant memory. TyxonQ provides several strategies for memory optimization:

.. code-block:: python

   import tyxonq as tq
   import gc
   
   # Strategy 1: Use context managers for temporary circuits
   def process_large_circuit():
       with tq.memory_context():
           circuit = tq.Circuit(30)
           # ... build large circuit ...
           result = circuit.run()
           return result  # Context cleans up intermediate states
   
   # Strategy 2: Explicit cleanup for long-running processes
   def batch_processing(circuits):
       results = []
       for i, circuit in enumerate(circuits):
           result = circuit.run()
           results.append(result)
           
           # Clean up every 10 circuits
           if i % 10 == 0:
               gc.collect()
               tq.clear_cache()
       
       return results

**Backend Memory Management**

.. code-block:: python

   from tyxonq.numerics import set_backend
   import torch
   
   # GPU memory management with PyTorch backend
   set_backend('pytorch')
   
   def gpu_memory_efficient_simulation():
       try:
           # Monitor GPU memory usage
           if torch.cuda.is_available():
               print(f"GPU memory before: {torch.cuda.memory_allocated()/1e9:.2f} GB")
           
           # Use mixed precision for memory savings
           with torch.cuda.amp.autocast():
               circuit = tq.Circuit(25).random_circuit(depth=10)
               result = circuit.run()
           
           # Explicit GPU cache cleanup
           if torch.cuda.is_available():
               torch.cuda.empty_cache()
               print(f"GPU memory after: {torch.cuda.memory_allocated()/1e9:.2f} GB")
           
           return result
       except torch.cuda.OutOfMemoryError:
           # Fallback to CPU
           print("GPU OOM, falling back to CPU")
           set_backend('numpy')
           return circuit.run()

GPU Acceleration
----------------

**Optimal Backend Selection**

.. code-block:: python

   import tyxonq as tq
   from tyxonq.numerics import set_backend
   
   def auto_select_backend(num_qubits):
       """Automatically select optimal backend based on problem size."""
       
       if num_qubits <= 15:
           # Small circuits: NumPy is sufficient
           set_backend('numpy')
           return 'cpu'
       
       elif num_qubits <= 25:
           # Medium circuits: Try GPU acceleration
           try:
               import torch
               if torch.cuda.is_available():
                   set_backend('pytorch')
                   torch.cuda.empty_cache()
                   return 'pytorch_gpu'
           except ImportError:
               pass
           
           # Fallback to CuPy if available
           try:
               import cupy
               set_backend('cupy')
               return 'cupy'
           except ImportError:
               set_backend('numpy')
               return 'cpu'
       
       else:
           # Large circuits: Prefer MPS simulator
           print(f"Warning: {num_qubits} qubits is large. Consider MPS simulator.")
           set_backend('numpy')  # MPS doesn't require specific backend
           return 'mps'

**Batch GPU Processing**

.. code-block:: python

   from tyxonq.numerics import vectorize_or_fallback
   import numpy as np
   
   def batch_vqe_optimization():
       """Vectorized VQE parameter optimization on GPU."""
       
       set_backend('pytorch')
       
       # Define parameterized circuit
       def vqe_circuit(params):
           circuit = tq.Circuit(4)
           for i, param in enumerate(params):
               circuit.ry(i % 4, param)
               if i % 2 == 1:
                   circuit.cnot(i % 4, (i + 1) % 4)
           return circuit.expectation(hamiltonian)
       
       # Vectorize over parameter batches
       vectorized_vqe = vectorize_or_fallback(vqe_circuit)
       
       # Process multiple parameters simultaneously
       param_batch = np.random.rand(100, 8) * 2 * np.pi  # 100 parameter sets
       
       # Single GPU call processes entire batch
       energies = vectorized_vqe(param_batch)
       
       return energies

Algorithmic Optimizations
-------------------------

**Light Cone Simplification**

.. code-block:: python

   def optimize_measurement_circuit(circuit, measured_qubits):
       """Apply light cone optimization to remove irrelevant operations."""
       
       # Compile with light cone simplification
       optimized = circuit.compile(
           options={
               'optimization_level': 3,
               'light_cone_simplification': True,
               'measured_qubits': measured_qubits
           }
       )
       
       print(f"Original gates: {len(circuit.ops)}")
       print(f"Optimized gates: {len(optimized.ops)}")
       
       return optimized

**Circuit Decomposition Strategies**

.. code-block:: python

   def custom_decomposition_strategy():
       """Use custom gate decomposition for better performance."""
       
       circuit = tq.Circuit(4)
       
       # Instead of direct multi-qubit gates
       # circuit.ccx(0, 1, 2)  # Expensive Toffoli
       
       # Use optimized decomposition
       circuit.h(2)
       circuit.cnot(1, 2)
       circuit.tdg(2)
       circuit.cnot(0, 2)
       circuit.t(2)
       circuit.cnot(1, 2)
       circuit.tdg(2)
       circuit.cnot(0, 2)
       circuit.t(1).t(2).h(2)
       circuit.cnot(0, 1)
       circuit.t(0).tdg(1)
       circuit.cnot(0, 1)
       
       return circuit

Custom Backend Development
==========================

Numerical Backend Interface
---------------------------

**Implementing ArrayBackend Protocol**

.. code-block:: python

   from tyxonq.numerics.api import ArrayBackend
   import numpy as np
   
   class CustomBackend(ArrayBackend):
       """Custom numerical backend implementation."""
       
       name = "custom"
       
       def __init__(self):
           self._rng_state = np.random.RandomState(42)
       
       # Required array operations
       def array(self, data, dtype=None):
           return np.array(data, dtype=dtype)
       
       def zeros(self, shape, dtype=None):
           return np.zeros(shape, dtype=dtype)
       
       def ones(self, shape, dtype=None):
           return np.ones(shape, dtype=dtype)
       
       def eye(self, n, dtype=None):
           return np.eye(n, dtype=dtype)
       
       # Mathematical operations
       def matmul(self, a, b):
           return np.matmul(a, b)
       
       def einsum(self, equation, *operands):
           return np.einsum(equation, *operands)
       
       def kron(self, a, b):
           return np.kron(a, b)
       
       # Random number generation
       def rng(self, seed=None):
           if seed is not None:
               self._rng_state = np.random.RandomState(seed)
           return self._rng_state
       
       def normal(self, rng, shape, mean=0, std=1):
           return rng.normal(mean, std, size=shape)
       
       # Type conversion
       def to_numpy(self, arr):
           return np.asarray(arr)
       
       # Optional: automatic differentiation
       def requires_grad(self, arr, flag=True):
           # Custom autodiff implementation
           return arr  # Placeholder
       
       def detach(self, arr):
           return arr  # Placeholder

**Registering Custom Backend**

.. code-block:: python

   # Register the custom backend
   from tyxonq.numerics.context import set_backend
   
   # Method 1: Register by instance
   custom_backend = CustomBackend()
   set_backend(custom_backend)
   
   # Method 2: Register by module path
   # set_backend('mypackage.backends.custom:CustomBackend')
   
   # Use the custom backend
   circuit = tq.Circuit(2).h(0).cnot(0, 1)
   result = circuit.run()

Device Simulator Development
----------------------------

**Custom Device Implementation**

.. code-block:: python

   from tyxonq.devices.base import DeviceBase
   from tyxonq.core.ir import Circuit
   
   class NoiseAwareSimulator(DeviceBase):
       """Custom device with built-in noise modeling."""
       
       name = "noise_aware"
       capabilities = {
           "supports_shots": True,
           "supports_noise": True,
           "max_qubits": 30
       }
       
       def __init__(self, noise_model=None):
           super().__init__()
           self.noise_model = noise_model or {}
       
       def run(self, circuit: Circuit, shots: int = 1000, **kwargs):
           """Execute circuit with noise simulation."""
           
           # Apply noise model to circuit
           noisy_circuit = self._apply_noise(circuit)
           
           # Simulate using density matrix for noise
           if self.noise_model:
               result = self._simulate_with_noise(noisy_circuit, shots)
           else:
               result = self._simulate_ideal(noisy_circuit, shots)
           
           return {
               "counts": result,
               "metadata": {
                   "shots": shots,
                   "noise_model": self.noise_model,
                   "device": self.name
               }
           }
       
       def _apply_noise(self, circuit):
           """Apply noise model to circuit operations."""
           
           noisy_ops = []
           for op in circuit.ops:
               noisy_ops.append(op)
               
               # Add depolarizing noise after gates
               if op[0] in ['h', 'x', 'y', 'z', 'cnot']:
                   p_depol = self.noise_model.get('depolarizing', 0.01)
                   if np.random.rand() < p_depol:
                       # Add random Pauli error
                       error_gate = np.random.choice(['x', 'y', 'z'])
                       if len(op) > 1:  # Has qubit indices
                           qubit = op[1] if isinstance(op[1], int) else op[1][0]
                           noisy_ops.append((error_gate, qubit))
           
           return Circuit(
               num_qubits=circuit.num_qubits,
               ops=noisy_ops,
               metadata=circuit.metadata
           )
       
       def _simulate_with_noise(self, circuit, shots):
           # Use density matrix simulation
           return circuit.device('density_matrix').run(shots=shots)
       
       def _simulate_ideal(self, circuit, shots):
           # Use statevector simulation
           return circuit.device('statevector').run(shots=shots)

**Device Registration and Usage**

.. code-block:: python

   # Register custom device
   from tyxonq.plugins.registry import get_device
   
   # Method 1: Direct instantiation
   noise_model = {'depolarizing': 0.02, 'readout': 0.05}
   custom_device = NoiseAwareSimulator(noise_model=noise_model)
   
   # Method 2: Plugin registration (recommended)
   def create_noise_aware_device(**kwargs):
       return NoiseAwareSimulator(**kwargs)
   
   # Use the custom device
   circuit = tq.Circuit(3).h(0).cnot(0, 1).cnot(1, 2)
   result = custom_device.run(circuit, shots=1000)
   
   print(f"Device: {result['metadata']['device']}")
   print(f"Counts: {result['counts']}")

Plugin System
=============

Plugin Architecture
-------------------

TyxonQ uses a registry-based plugin system for extensibility:

.. mermaid::

   graph TD
       A[Plugin Registry] --> B[Device Plugins]
       A --> C[Compiler Plugins]
       A --> D[Backend Plugins]
       
       B --> B1[Custom Simulators]
       B --> B2[Hardware Drivers]
       B --> B3[Noise Models]
       
       C --> C1[Optimization Passes]
       C --> C2[Target Compilers]
       C --> C3[Custom Decompositions]
       
       D --> D1[Numerical Backends]
       D --> D2[Autodiff Engines]
       D --> D3[GPU Accelerators]

**Plugin Discovery**

.. code-block:: python

   from tyxonq.plugins.registry import discover, get_device, get_compiler
   
   # Discover available plugins
   device_plugins = discover('tyxonq.devices')
   compiler_plugins = discover('tyxonq.compilers')
   
   print(f"Available devices: {list(device_plugins.keys())}")
   print(f"Available compilers: {list(compiler_plugins.keys())}")
   
   # Load plugin by fully-qualified path
   custom_device = get_device('mypackage.devices:MyCustomDevice')
   custom_compiler = get_compiler('mypackage.compilers:MyOptimizer')

Creating Custom Plugins
-----------------------

**Custom Compiler Plugin**

.. code-block:: python

   from tyxonq.compiler.api import CompileResult, Pass
   from tyxonq.core.ir import Circuit
   
   class CustomOptimizationPass(Pass):
       """Custom optimization pass for domain-specific circuits."""
       
       name = "custom_optimization"
       
       def execute(self, circuit: Circuit, options: dict) -> Circuit:
           """Apply custom optimization logic."""
           
           optimized_ops = []
           for i, op in enumerate(circuit.ops):
               # Custom optimization logic
               if self._should_optimize(op, circuit.ops[i:i+2]):
                   optimized_ops.extend(self._apply_optimization(op))
               else:
                   optimized_ops.append(op)
           
           return Circuit(
               num_qubits=circuit.num_qubits,
               ops=optimized_ops,
               metadata=circuit.metadata
           )
       
       def _should_optimize(self, op, lookahead):
           """Determine if operation should be optimized."""
           # Custom logic here
           return len(lookahead) >= 2 and lookahead[1][0] == 'h'
       
       def _apply_optimization(self, op):
           """Apply specific optimization."""
           # Return optimized operation sequence
           return [op]  # Placeholder
   
   class CustomCompiler:
       """Custom compiler with domain-specific optimizations."""
       
       name = "domain_specific"
       
       def compile(self, circuit: Circuit, options: dict) -> CompileResult:
           # Apply custom optimization pass
           optimizer = CustomOptimizationPass()
           optimized_circuit = optimizer.execute(circuit, options)
           
           return CompileResult(
               circuit=optimized_circuit,
               metadata={
                   'compiler': self.name,
                   'optimizations_applied': ['custom_optimization'],
                   'original_gates': len(circuit.ops),
                   'optimized_gates': len(optimized_circuit.ops)
               }
           )

**Plugin Registration**

.. code-block:: python

   # File: mypackage/plugins.py
   
   from tyxonq.plugins.registry import get_compiler, get_device
   
   # Register plugins
   def register_plugins():
       """Register all custom plugins."""
       
       # This would be called during package initialization
       pass
   
   # Usage
   def use_custom_plugins():
       # Load by module path
       compiler = get_compiler('mypackage.plugins:CustomCompiler')
       device = get_device('mypackage.plugins:NoiseAwareSimulator')
       
       # Use in circuit compilation
       circuit = tq.Circuit(4).random_circuit(depth=5)
       compiled = compiler.compile(circuit, {})
       result = device.run(compiled.circuit, shots=1000)
       
       return result

Framework Extension
===================

Domain-Specific Applications
----------------------------

**Building Quantum Chemistry Extensions**

.. code-block:: python

   from tyxonq.applications.chem import Molecule
   import tyxonq as tq
   
   class CustomChemistryApp:
       """Domain-specific quantum chemistry application."""
       
       def __init__(self, molecule: Molecule):
           self.molecule = molecule
           self.hamiltonian = molecule.get_hamiltonian()
       
       def custom_vqe_ansatz(self, params):
           """Domain-specific VQE ansatz for this molecule type."""
           
           n_qubits = self.molecule.n_qubits
           circuit = tq.Circuit(n_qubits)
           
           # Custom ansatz based on molecular structure
           if self.molecule.is_linear():
               circuit = self._linear_molecule_ansatz(circuit, params)
           elif self.molecule.is_aromatic():
               circuit = self._aromatic_ansatz(circuit, params)
           else:
               circuit = self._general_ansatz(circuit, params)
           
           return circuit
       
       def _linear_molecule_ansatz(self, circuit, params):
           """Optimized ansatz for linear molecules."""
           # Implementation specific to linear molecules
           return circuit
       
       def optimize_ground_state(self):
           """Find ground state using custom methods."""
           
           from tyxonq.libs.optimizer import soap
           
           def energy_function(params):
               circuit = self.custom_vqe_ansatz(params)
               return circuit.expectation(self.hamiltonian)
           
           # Use custom optimizer
           result = soap(
               fun=energy_function,
               x0=np.random.rand(self.molecule.n_params) * 0.1,
               maxfev=1000
           )
           
           return result

**Creating Custom Algorithm Libraries**

.. code-block:: python

   # File: mypackage/algorithms/custom_qaoa.py
   
   import tyxonq as tq
   import numpy as np
   
   class AdaptiveQAOA:
       """Adaptive QAOA with custom optimization strategies."""
       
       def __init__(self, problem_hamiltonian, mixer_hamiltonian=None):
           self.H_problem = problem_hamiltonian
           self.H_mixer = mixer_hamiltonian or self._default_mixer()
           self.adaptive_layers = []
       
       def _default_mixer(self):
           """Default X-mixer for QAOA."""
           # Implementation
           pass
       
       def adaptive_layer_selection(self, current_state):
           """Adaptively select next QAOA layer."""
           
           # Analyze current state properties
           entanglement = self._measure_entanglement(current_state)
           energy_gap = self._estimate_energy_gap(current_state)
           
           if entanglement < 0.5:
               return 'entangling_layer'
           elif energy_gap > 0.1:
               return 'problem_layer'
           else:
               return 'mixer_layer'
       
       def run_adaptive_qaoa(self, max_layers=10):
           """Run adaptive QAOA optimization."""
           
           circuit = tq.Circuit(self.n_qubits)
           
           for layer in range(max_layers):
               # Get current state
               current_state = circuit.statevector()
               
               # Adaptively select next layer
               layer_type = self.adaptive_layer_selection(current_state)
               
               # Add appropriate layer
               if layer_type == 'entangling_layer':
                   circuit = self._add_entangling_layer(circuit)
               elif layer_type == 'problem_layer':
                   circuit = self._add_problem_layer(circuit)
               else:
                   circuit = self._add_mixer_layer(circuit)
               
               # Check convergence
               energy = circuit.expectation(self.H_problem)
               if self._converged(energy):
                   break
           
           return circuit, energy

Profiling and Benchmarking
==========================

Performance Profiling
----------------------

**Built-in Profiling Tools**

.. code-block:: python

   import tyxonq as tq
   from tyxonq.utils import benchmark, profile_memory
   
   # Benchmark function execution
   def test_circuit_performance():
       circuit = tq.Circuit(20).random_circuit(depth=10)
       
       # Benchmark execution time
       result, time_stats, memory_stats = benchmark(
           lambda: circuit.run(shots=1000),
           tries=5,
           memory_profile=True
       )
       
       print(f"Average time: {time_stats['mean']:.3f}s")
       print(f"Std deviation: {time_stats['std']:.3f}s")
       print(f"Peak memory: {memory_stats['peak']:.2f} MB")
       
       return result
   
   # Memory profiling for large circuits
   @profile_memory
   def memory_intensive_simulation():
       circuits = []
       for i in range(100):
           circuit = tq.Circuit(15).random_circuit(depth=5)
           circuits.append(circuit)
       
       results = [c.run() for c in circuits]
       return results

**Custom Profiling**

.. code-block:: python

   import time
   import psutil
   import functools
   
   def advanced_profiler(func):
       """Advanced profiling decorator."""
       
       @functools.wraps(func)
       def wrapper(*args, **kwargs):
           # Start profiling
           start_time = time.perf_counter()
           start_memory = psutil.Process().memory_info().rss / 1024 / 1024
           
           # Track GPU memory if available
           gpu_memory_start = 0
           try:
               import torch
               if torch.cuda.is_available():
                   gpu_memory_start = torch.cuda.memory_allocated() / 1024 / 1024
           except ImportError:
               pass
           
           # Execute function
           result = func(*args, **kwargs)
           
           # End profiling
           end_time = time.perf_counter()
           end_memory = psutil.Process().memory_info().rss / 1024 / 1024
           
           gpu_memory_end = 0
           try:
               if torch.cuda.is_available():
                   gpu_memory_end = torch.cuda.memory_allocated() / 1024 / 1024
           except:
               pass
           
           # Report
           print(f"Function: {func.__name__}")
           print(f"Execution time: {end_time - start_time:.3f}s")
           print(f"CPU memory change: {end_memory - start_memory:.2f} MB")
           if gpu_memory_end > 0:
               print(f"GPU memory change: {gpu_memory_end - gpu_memory_start:.2f} MB")
           
           return result
       
       return wrapper

Benchmarking Strategies
-----------------------

**Comparative Benchmarks**

.. code-block:: python

   def benchmark_backends():
       """Compare performance across different backends."""
       
       backends = ['numpy', 'pytorch']
       if tq.backend_available('cupy'):
           backends.append('cupy')
       
       results = {}
       
       for backend_name in backends:
           try:
               tq.set_backend(backend_name)
               
               # Standard benchmark circuit
               circuit = tq.Circuit(20)
               for i in range(20):
                   circuit.h(i)
               for i in range(19):
                   circuit.cnot(i, i+1)
               
               # Benchmark execution
               times = []
               for _ in range(10):
                   start = time.perf_counter()
                   circuit.run()
                   times.append(time.perf_counter() - start)
               
               results[backend_name] = {
                   'mean_time': np.mean(times),
                   'std_time': np.std(times),
                   'min_time': np.min(times)
               }
               
           except Exception as e:
               print(f"Backend {backend_name} failed: {e}")
               results[backend_name] = None
       
       return results

**Scalability Analysis**

.. code-block:: python

   def analyze_scalability():
       """Analyze performance scaling with system size."""
       
       qubit_counts = range(10, 26, 2)
       results = []
       
       for n_qubits in qubit_counts:
           print(f"Testing {n_qubits} qubits...")
           
           try:
               # Create test circuit
               circuit = tq.Circuit(n_qubits)
               for i in range(n_qubits):
                   circuit.h(i)
               for i in range(n_qubits - 1):
                   circuit.cnot(i, i+1)
               
               # Measure execution time
               start = time.perf_counter()
               result = circuit.run()
               execution_time = time.perf_counter() - start
               
               # Measure memory usage
               memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
               
               results.append({
                   'qubits': n_qubits,
                   'time': execution_time,
                   'memory': memory_mb,
                   'success': True
               })
               
           except Exception as e:
               results.append({
                   'qubits': n_qubits,
                   'error': str(e),
                   'success': False
               })
               break
       
       return results

Best Practices
==============

Performance Guidelines
-----------------------

1. **Choose Appropriate Backends**:
   
   .. code-block:: python
   
      # For small circuits (< 15 qubits)
      tq.set_backend('numpy')
      
      # For medium circuits with gradients
      tq.set_backend('pytorch')
      
      # For large pure simulations
      tq.set_backend('cupy')  # if available

2. **Memory Management**:
   
   .. code-block:: python
   
      # Use context managers
      with tq.memory_context():
          result = large_circuit.run()
      
      # Explicit cleanup in loops
      for circuit in circuit_batch:
          result = circuit.run()
          if i % 100 == 0:
              tq.clear_cache()

3. **Vectorization**:
   
   .. code-block:: python
   
      # Prefer vectorized operations
      vectorized_fn = tq.vectorize_or_fallback(circuit_function)
      results = vectorized_fn(parameter_batch)
      
      # Over sequential loops
      # results = [circuit_function(p) for p in parameter_batch]

Framework Extension Guidelines
------------------------------

1. **Plugin Development**:
   - Follow the registry pattern for discoverability
   - Implement proper error handling and validation
   - Provide comprehensive documentation and examples

2. **Custom Backend Development**:
   - Implement the full ArrayBackend protocol
   - Ensure numerical accuracy and stability
   - Provide clear performance characteristics

3. **Testing and Validation**:
   - Create comprehensive test suites for custom components
   - Validate against known benchmarks
   - Document performance characteristics and limitations

See Also
========

- :doc:`../core/index` - Core Module fundamentals
- :doc:`../numerics/index` - Numerics Backend system
- :doc:`../../developer_guide/index` - Developer Guide
- :doc:`../../examples/index` - Advanced Examples
- :doc:`../../api/index` - Complete API Reference

Further Reading
===============

**Performance Optimization**

.. [Gottesman1998] D. Gottesman,  
   "The Heisenberg Representation of Quantum Computers",  
   arXiv:quant-ph/9807006 (1998)

.. [Vidal2003] G. Vidal,  
   "Efficient Classical Simulation of Slightly Entangled Quantum Computations",  
   Physical Review Letters, 91, 147902 (2003)

**Framework Design**

.. [Smith2016] R. S. Smith et al.,  
   "A Practical Quantum Instruction Set Architecture",  
   arXiv:1608.03355 (2016)

.. [Cross2017] A. W. Cross et al.,  
   "Open Quantum Assembly Language",  
   arXiv:1707.03429 (2017)

**GPU Acceleration**

.. [Nvidia2021] NVIDIA Corporation,  
   "CUDA Best Practices Guide",  
   NVIDIA Developer Documentation (2021)

.. [PyTorch2019] A. Paszke et al.,  
   "PyTorch: An Imperative Style, High-Performance Deep Learning Library",  
   NeurIPS (2019)